{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"outputs/final_df.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['calendar_updated'] = pd.to_datetime(df['calendar_updated'])\n",
    "df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "df['host_since'] = pd.to_datetime(df['host_since'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed train description\n",
      "Transformed test description\n",
      "Trained desc regressor\n",
      "Transformed train neighborhood\n",
      "Transformed test neighborhood\n",
      "Trained neigh regressor\n",
      "Transformed train host\n",
      "Transformed test host\n",
      "Trained host regressor\n",
      "Encoded X\n",
      "Trained final model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from lightgbm import LGBMRegressor\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from image_reg import abb_dataset, Net\n",
    "\n",
    "desc_tfidf = TfidfVectorizer(stop_words='english')\n",
    "neigh_tfidf = TfidfVectorizer(stop_words='english')\n",
    "host_tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X = df.drop(['price', 'id', 'listing_url', 'scrape_id',\n",
    "             'last_scraped',\n",
    "             'picture_url', 'host_id', 'host_url', 'host_name',\n",
    "             'host_thumbnail_url', 'host_picture_url', 'calendar_last_scraped',\n",
    "             ], axis=1)\n",
    "X['calendar_updated'] = pd.to_numeric(pd.to_datetime(X['calendar_updated']))\n",
    "X['host_since'] = pd.to_numeric(pd.to_datetime(X['host_since']))\n",
    "X['first_review'] = pd.to_numeric(pd.to_datetime(X['first_review']))\n",
    "X['last_review'] = pd.to_numeric(pd.to_datetime(X['last_review']))\n",
    "\n",
    "y = df['price']\n",
    "y = y.str.replace('$', '', regex=False).str.replace('.', '', regex=False).str.replace(',','', regex=False).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "desc_vec = desc_tfidf.fit_transform(X_train['description'].replace(np.nan, ' '))\n",
    "print('Transformed train description')\n",
    "desc_vec_test = desc_tfidf.transform(X_test['description'].replace(np.nan, ' '))\n",
    "print('Transformed test description')\n",
    "desc_reg = LGBMRegressor(random_state=0).fit(desc_vec, y_train)\n",
    "X_train['desc_pred'] = desc_reg.predict(desc_vec)\n",
    "X_test['desc_pred'] = desc_reg.predict(desc_vec_test)\n",
    "print('Trained desc regressor')\n",
    "\n",
    "neigh_vec = neigh_tfidf.fit_transform(X_train['neighborhood_overview'].replace(np.nan, ' '))\n",
    "print('Transformed train neighborhood')\n",
    "neigh_vec_test = neigh_tfidf.transform(X_test['neighborhood_overview'].replace(np.nan, ' '))\n",
    "print('Transformed test neighborhood')\n",
    "neigh_reg = LGBMRegressor(random_state=0).fit(neigh_vec, y_train)\n",
    "X_train['neigh_pred'] = neigh_reg.predict(neigh_vec)\n",
    "X_test['neigh_pred'] = neigh_reg.predict(neigh_vec_test)\n",
    "print('Trained neigh regressor')\n",
    "\n",
    "host_vec = host_tfidf.fit_transform(X_train['host_about'].replace(np.nan, ' '))\n",
    "print('Transformed train host')\n",
    "host_vec_test = host_tfidf.transform(X_test['host_about'].replace(np.nan, ' '))\n",
    "print('Transformed test host')\n",
    "host_reg = LGBMRegressor(random_state=0).fit(host_vec, y_train)\n",
    "X_train['host_pred'] = host_reg.predict(host_vec)\n",
    "X_test['host_pred'] = host_reg.predict(host_vec_test)\n",
    "print('Trained host regressor')\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('../models/cnn'))\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = abb_dataset(csv_file='data/faces/face_landmarks.csv',\n",
    "                        root='./outputs', train=True,\n",
    "                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = abb_dataset(csv_file='data/faces/face_landmarks.csv',\n",
    "                    root='./outputs', train=False,\n",
    "                    download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "X_train['host_pred'] = net(trainloader)\n",
    "X_test['host_pred'] = net(testloader)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "X_train.drop(['description', 'neighborhood_overview', 'host_about'], axis=1, inplace=True)\n",
    "\n",
    "X_test.drop(['description', 'neighborhood_overview', 'host_about'], axis=1, inplace=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "X_train = enc.fit_transform(X_train)\n",
    "X_test = enc.transform(X_test)\n",
    "\n",
    "print('Encoded X')\n",
    "\n",
    "reg = LGBMRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "print('Trained final model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/final_reg.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(desc_reg, 'models/desc_reg.joblib')\n",
    "dump(neigh_reg, 'models/neigh_reg.joblib')\n",
    "dump(host_reg, 'models/host_reg.joblib')\n",
    "dump(enc, 'models/enc.joblib')\n",
    "dump(reg, 'models/final_reg.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24254563551258135"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c787b725c66bd5fb201d414dc3eb4cc2b2cf4abf2e7b15a87f1db6cefb8aee3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
